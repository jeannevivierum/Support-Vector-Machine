{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Support Vector Machine\n",
        "subtitle: Jeanne Vivier\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "---"
      ],
      "id": "3f369ea7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| include: false\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path(\"..\") / \"Code\"))\n",
        "from svm_source import *\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.decomposition import PCA\n",
        "from time import time\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.style.use('ggplot')"
      ],
      "id": "ccc8809d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "Les machines à vecteurs de support (Support Vector Machine, SVM, en anglais), sont un ensemble de méthodes d'apprentissage supervisé utilisées pour la classification, la régression et la détection des valeurs aberrantes. La popularité des méthodes SVM, pour la classification binaire en particulier, provient du fait qu’elles reposent sur l’application d’algorithmes de recherche de règles de décision linéaires : on parle d’hyperplans (affines) séparateurs.  \n",
        "Le code complet est disponible dans le fichier $\\texttt{svm\\_script.py}$ dans le dossier $\\texttt{Code}$.   \n",
        "Dans ce compte rendu, nous avons fixé une graine $\\texttt{np.random.seed(1234)}$ pour la reproductibilité des résultats. \n",
        "\n",
        "## Question 1\n",
        "\n",
        "Pour commencer, écrivons un code qui va classifier la classe 1 contre la classe 2 du dataset $\\texttt{iris}$ en utilisant les deux premières variables et un noyau linéaire.\n"
      ],
      "id": "57079020"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np.random.seed(1234)\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X = X[y != 0, :2]\n",
        "y = y[y != 0]\n",
        "\n",
        "parameters = {'kernel': ['linear'], 'C': list(np.logspace(-3, 3, 200))}\n",
        "\n",
        "n_iterations = 50\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for i in range(n_iterations):\n",
        "\n",
        "    X, y = shuffle(X, y)\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=i)\n",
        "    \n",
        "    clf_linear = GridSearchCV(SVC(), parameters, n_jobs=-1)\n",
        "    \n",
        "    clf_linear.fit(X_train, y_train)\n",
        "    \n",
        "    train_scores.append(clf_linear.score(X_train, y_train))\n",
        "    test_scores.append(clf_linear.score(X_test, y_test))\n",
        "\n",
        "moy_train_score = np.mean(train_scores)\n",
        "moy_test_score = np.mean(test_scores)\n",
        "\n",
        "print(f'Mean generalization score over {n_iterations} iterations:')\n",
        "print(f'Train score: {moy_train_score}')\n",
        "print(f'Test score: {moy_test_score}')"
      ],
      "id": "0f518f76",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous séparons donc aléatoirement le jeu de données en deux parties. L'une est réservée à l'entraîenement et l'autre au test. Nous calculons alors les scores obtnus pour chacun des échantillons pour un noyau linéaire. Nous réitérons cette action 50 fois, afin d'obtenir les scores moyens des deux échantillons :  \n",
        "- Le score moyen de l'échantillon d'entraînement : $0.7148$   \n",
        "- Le score moyen de l'échantillon de test : $0.674$\n",
        "\n",
        "Le socre moyen de l'échantillon d'entraînement est légèremenr supérieur à celui de l'échantillon test. Ce résultat semble pluôt cohérent, le modèle est plus performant sur les données avec lesquelles il s'est entraîné, puisqu'il les a déjà \"vues\". De plus, un écart entre le score d'entraînement et le score de test est indicateur d'overfitting : le modèle à \"surapprit\" sur les données d'apprentissage. Ici, l'écart est assez faible, le modèle n'a pas trop de mal à généraliser ce qu'il a apprit sur l'échantillon d'entraînement. \n",
        "\n",
        "\n",
        "## Question 2\n",
        "\n",
        "Nous voulons alors comparer ce résultat avec un SVM basé sur noyau polynomial.\n"
      ],
      "id": "56d48c87"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np.random.seed(346)\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "X = scaler.fit_transform(X)\n",
        "y = iris.target\n",
        "X = X[y != 0, :2]\n",
        "y = y[y != 0]\n",
        "\n",
        "# split train test\n",
        "X, y = shuffle(X, y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "###############################################################################\n",
        "gammas = list(map(float, 10. ** np.arange(1, 2)))\n",
        "degrees = list(map(int, np.r_[1, 2, 3]))\n",
        "\n",
        "# Définition de la grille de paramètres\n",
        "parameters = {'kernel': ['poly'], 'C': Cs, 'gamma': gammas, 'degree': degrees}\n",
        "\n",
        "# Utilisation de GridSearchCV\n",
        "clf_poly = GridSearchCV(SVC(), param_grid=parameters, n_jobs=-1)\n",
        "clf_poly.fit(X_train, y_train)\n",
        "\n",
        "# Affichage des meilleurs paramètres avec les bons types\n",
        "print(clf_poly.best_params_)\n",
        "\n",
        "\n",
        "#%%\n",
        "# display your results using frontiere\n",
        "\n",
        "def f_linear(xx):\n",
        "    \"\"\"Classifier: needed to avoid warning due to shape issues\"\"\"\n",
        "    return clf_linear.predict(xx.reshape(1, -1))\n",
        "\n",
        "def f_poly(xx):\n",
        "    \"\"\"Classifier: needed to avoid warning due to shape issues\"\"\"\n",
        "    return clf_poly.predict(xx.reshape(1, -1))\n",
        "\n",
        "plt.ion()\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(131)\n",
        "plot_2d(X, y)\n",
        "plt.title(\"iris dataset\")\n",
        "\n",
        "plt.subplot(132)\n",
        "frontiere(f_linear, X, y)\n",
        "plt.title(\"linear kernel\")\n",
        "\n",
        "plt.subplot(133)\n",
        "frontiere(f_poly, X, y)\n",
        "\n",
        "plt.title(\"polynomial kernel\")\n",
        "plt.tight_layout()\n",
        "plt.draw()"
      ],
      "id": "3ec186e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les résultats obtenus sont, à première vue, assez troublants. En effet, le noyau polynômial offre un résultat très proche de celui du noyau linéaire. Il s'agit d'un polynôme de degré 1, donc une fonction linéaire (ou plutôt affine mais c'est un abus de langage). La graine est fixée, pour faciliter l'interprétation des résultats, mais en changeant la graine, il arrive d'obtenir des résultats différents: certaines frontières obtenues avec le noyau polynomial ont bel et bien un aspcet polynomial (par exemple avec la graine 567 (`np.random.seed(567)`) ou sans graine du tout, et en exécutant le code plusieurs fois).\n",
        "\n",
        "# SVM GUI\n",
        "\n",
        "Nous lançons le script $\\texttt{svm\\_gui.py}$ disponible dans la section $\\texttt{Code}$. Cette application permet, en temps réel, d’évaluer l’impact du choix du noyau et du paramètre de régularisation C.\n",
        "\n",
        "## Question 3\n",
        "\n",
        "Nous générons alors des jeux de données très déséquilibré avec beaucoup plus de points dans une classe que dans l’autre (au moins 90% pour la rouge vs 10% pour la noire).\n",
        "\n",
        "::: {.grid}\n",
        "::: {.g-col-4}\n",
        "![C=0.1](Images/01.png)\n",
        ":::\n",
        "::: {.g-col-4}\n",
        "![C=0.01](Images/001.png)\n",
        ":::\n",
        "::: {.g-col-4}\n",
        "![C=0.005](Images/0005.png)\n",
        ":::\n",
        ":::\n",
        "\n",
        "Sur les figures ci- dessus, nous pouvons observer les hyperplans séparateurs (lignes noires continues), ainsi que les marges maximales (lignes noires en pointillés). Plus la constante C est grande plus la marge entre la frontière et les observations (points rouges et noirs) est petite. C'est le phénomène de surajustement, on veut \"trop bien\" séparer les deux couleurs.    \n",
        "En revanche, lorsque C est petite, la marge entre la frontière et les points de couleurs devient très grande, jusqu'à englober complètement les points dont la couleur est minoritaire.    \n",
        "Cependant, le classifier ne semble pas donner de poids particulier au nuage de points rouges. \n",
        " \n",
        "\n",
        "# Classification de visages\n",
        "\n",
        "Intéressons nous maintenant à un problème de classification de visages.\n",
        "Pour cela, nous utiliserons le jeu de données <i>Labeled Faces in the Wild</i> (<i>LWF</i>).  \n",
        "Dans la suite, nous ne nous intéresserons qu'à deux visages, ceux de Tony Blair et Collin Powell.\n"
      ],
      "id": "a5f831e7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 6,
        "fig-height": 4
      },
      "source": [
        "#| fig-cap: Visage de Tony Blair dans la base de données\n",
        "#| fig-align: center\n",
        "\n",
        "\"\"\"\n",
        "The dataset used in this example is a preprocessed excerpt\n",
        "of the \"Labeled Faces in the Wild\", aka LFW_:\n",
        "\n",
        "  http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (233MB)\n",
        "\n",
        "  _LFW: http://vis-www.cs.umass.edu/lfw/\n",
        "\"\"\"\n",
        "np.random.seed(1234)\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4,\n",
        "                              color=True, funneled=False, slice_=None,\n",
        "                              download_if_missing=True)\n",
        "\n",
        "images = lfw_people.images\n",
        "n_samples, h, w, n_colors = images.shape\n",
        "\n",
        "target_names = lfw_people.target_names.tolist()\n",
        "\n",
        "names = ['Tony Blair', 'Colin Powell']\n",
        "\n",
        "\n",
        "idx0 = (lfw_people.target == target_names.index(names[0]))\n",
        "idx1 = (lfw_people.target == target_names.index(names[1]))\n",
        "images = np.r_[images[idx0], images[idx1]]\n",
        "n_samples = images.shape[0]\n",
        "y = np.r_[np.zeros(np.sum(idx0)), np.ones(np.sum(idx1))].astype(int)\n",
        "\n",
        "plot_gallery(images, np.arange(12))\n",
        "plt.show()\n",
        "\n",
        "X = (np.mean(images, axis=3)).reshape(n_samples, -1)\n",
        "\n",
        "\n",
        "X -= np.mean(X, axis=0)\n",
        "X /= np.std(X, axis=0)\n",
        "\n",
        "indices = np.random.permutation(X.shape[0])\n",
        "train_idx, test_idx = indices[:X.shape[0] // 2], indices[X.shape[0] // 2:]\n",
        "X_train, X_test = X[train_idx, :], X[test_idx, :]\n",
        "y_train, y_test = y[train_idx], y[test_idx]\n",
        "images_train, images_test = images[\n",
        "    train_idx, :, :, :], images[test_idx, :, :, :]"
      ],
      "id": "7f9e3cc7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 4\n",
        "\n",
        "Nous cherchons à montrer l'influence du paramètre de régularisation.\n"
      ],
      "id": "6df3a3d1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-cap: \n",
        "#|   - \"Score d'apprentissage en fonction de la valeur de C\"\n",
        "np.random.seed(1234)\n",
        "print(\"--- Linear kernel ---\")\n",
        "print(\"Fitting the classifier to the training set\")\n",
        "t0 = time()\n",
        "\n",
        "# fit a classifier (linear) and test all the Cs\n",
        "Cs = 10. ** np.arange(-5, 6)\n",
        "scores = []\n",
        "errors = []\n",
        "for C in Cs:\n",
        "\n",
        "    clf = SVC(kernel='linear', C=C)\n",
        "    clf.fit(X_train,y_train)\n",
        "\n",
        "    score = clf.score(X_train, y_train)\n",
        "    scores.append(score)\n",
        "\n",
        "ind = np.argmax(scores)\n",
        "print(\"Best C: {}\".format(Cs[ind]))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(Cs, scores)\n",
        "plt.xlabel(\"Parametres de regularisation C\")\n",
        "plt.ylabel(\"Scores d'apprentissage\")\n",
        "plt.xscale(\"log\")\n",
        "#plt.tight_layout()\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(\"Best score: {}\".format(np.max(scores)))\n",
        "\n",
        "print(\"Predicting the people names on the testing set\")\n",
        "t0 = time()"
      ],
      "id": "e9e2d7fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous remarquons alors que le score d'apprentissage augmente en même temps de la constante de tolérance C. Le score atteint alors un plateau lorsque C = $10^{-3}$, devenant ainsi le meilleur paramètre.  Notons que le score d'apprentissage n'est rien d'autre que 1 - l'erreur de prédiction.\n",
        "  \n",
        "Nous calculons alors la précision et son niveau de chance, en utilisant la valeur de C = $10^{-3}$ pour créer un nouveau classifier linéaire. Ce nouveau classifier est entraîné et testé.\n"
      ],
      "id": "db6c227a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np.random.seed(1234)\n",
        "t0=time()\n",
        "clf= SVC(kernel='linear', C=Cs[ind])\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "# fin du fait par moi, vérifier avec les autres\n",
        "\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "# The chance level is the accuracy that will be reached when constantly predicting the majority class.\n",
        "print(\"Chance level : %s\" % max(np.mean(y), 1. - np.mean(y)))\n",
        "print(\"Accuracy : %s\" % clf.score(X_test, y_test))"
      ],
      "id": "e6a55489",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous obtenons alors une précision de $0.942$, avec un niveau de chance de $0.621$.   \n",
        "Mais revenons-en à la classification des visages. \n"
      ],
      "id": "66da038c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np.random.seed(1234)\n",
        "#| layout-ncol: 2\n",
        "y_pred = clf.predict(X_test)\n",
        "prediction_titles = [title(y_pred[i], y_test[i], names)\n",
        "                     for i in range(y_pred.shape[0])]\n",
        "\n",
        "plot_gallery(images_test, prediction_titles)\n",
        "plt.show()\n",
        "\n",
        "####################################################################\n",
        "# Look at the coefficients\n",
        "plt.figure()\n",
        "plt.imshow(np.reshape(clf.coef_, (h, w)))\n",
        "plt.show()"
      ],
      "id": "173c095e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous pouvons comparer la prédiction à la vraie personne. Le modèle est plutôt bon. Sur les 12 photos de Blair et Powell, il ne commet aucune erreur. Ne nous emballons pas, il ne s'agit là que d'une réalisation, mais le classifier a tout de même une bonne précision  ($90\\%$).    \n",
        "La seconde figure met en évidence les parties du visage qui sont les plus utiles pour reconnaître une personne. Plus la zone est jaune, plus elle est importante pour distinguer un visage. Nous pouvons voir qu'il s'agit de la bouche, du haut du crâne, des yeux et de nez. \n",
        "\n",
        "\n",
        "## Question 5\n",
        "\n",
        "Nous ajoutons à présent des variables de nuisances ($\\texttt{X\\_noisy}$). Cela augmente ainsi le nombre de variables à nombre de points d’apprentissage fixé. \n",
        "Après implémentation, nous obtenons les résultats suivants : "
      ],
      "id": "1ba87b0b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np.random.seed(1234)\n",
        "def run_svm_cv(_X, _y):\n",
        "    _indices = np.random.permutation(_X.shape[0])\n",
        "    _train_idx, _test_idx = _indices[:_X.shape[0] // 2], _indices[_X.shape[0] // 2:]\n",
        "    _X_train, _X_test = _X[_train_idx, :], _X[_test_idx, :]\n",
        "    _y_train, _y_test = _y[_train_idx], _y[_test_idx]\n",
        "\n",
        "    _parameters = {'kernel': ['linear'], 'C': list(np.logspace(-3, 3, 5))}\n",
        "    _svr = svm.SVC()\n",
        "    _clf_linear = GridSearchCV(_svr, _parameters)\n",
        "    _clf_linear.fit(_X_train, _y_train)\n",
        "\n",
        "    print('Generalization score for linear kernel: %s, %s \\n' %\n",
        "          (_clf_linear.score(_X_train, _y_train), _clf_linear.score(_X_test, _y_test)))\n",
        "\n",
        "print(\"Score sans variable de nuisance\")\n",
        "\n",
        "run_svm_cv(X, y)\n",
        "\n",
        "\n",
        "print(\"Score avec variable de nuisance\")\n",
        "n_features = X.shape[1]\n",
        "# On rajoute des variables de nuisances\n",
        "sigma = 1\n",
        "noise = sigma * np.random.randn(n_samples, 300, )\n",
        "X_noisy = np.concatenate((X, noise), axis=1)\n",
        "X_noisy = X_noisy[np.random.permutation(X.shape[0])]\n",
        "\n",
        "run_svm_cv(X_noisy, y)"
      ],
      "id": "7c90ed0b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "|        | Entraîenement | Test      |\n",
        "|--------|--------|--------|\n",
        "| Score sans variable de nuisance  | 1.0  |   0.932     |\n",
        "| Score avec variables de nuisance   | 1.0   |    0.537    |\n",
        "\n",
        "\n",
        "Nous pouvons alors constater que la performance du modèle chute drastiquement lorsqu'on ajoute la variable de nuisance. De plus, l'écart entre le score de l'échantillon d'entraînement et de l'échantillon test est assez important lorsqu'on ajoute les variables de nuisance. Nous assistons au phénomène d'\"overfitting\", du à l'ajout de variables de nuisance. Ces dernières impactent fortement la capacité du modèle à s'adapter à de nouvelles données (les données de test).\n",
        "\n",
        "## Question 6\n",
        "\n",
        "Finalement, nous voudrions réduire les dimensions afin d'améliorer la précision du modèle. Autrement dit, nous aimerions voir si l'overfitting peut être corrigé par une diminution de la dimension. Dans le code pré-rempli dans le $\\texttt{svm\\_script.py}$, la recommendation était de choisir un nombre de composantes autour de $20$. Cette opération nécessitant beaucoup de temps de calcul, nous n'avons fait tourné le code que sur un seul ordinateur (celui de Quentin Festor). C'est donc ses résultats que nous interpèterons dans cette section.\n",
        "\n",
        "Voici donc les résultats qu'il a obtenu : \n",
        "\n",
        "| Nombre de composantes PCA | Score d'apprentissage | Score de test |\n",
        "|---------------------------|-----------------------|---------------|\n",
        "| 5                         | 0.6053                | 0.6158        |\n",
        "| 10                        | 0.6053                | 0.6368        |\n",
        "| 15                        | 0.6526                | 0.5895        |\n",
        "| 20                        | 0.6579                | 0.5895        |\n",
        "| 25                        | 0.6947                | 0.5842        |\n",
        "| 80                        | 0.7474                | 0.4895        |\n",
        "| 120                       | 1.0000                | 0.5263        |\n",
        "| 200                       | 0.9263                | 0.5211        |\n"
      ],
      "id": "dcb59dd9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "components = [5, 10, 15, 20, 25, 80, 120, 200]\n",
        "train_scores = [0.6053, 0.6053, 0.6526, 0.6579, 0.6947, 0.7474, 1.0000, 0.9263]\n",
        "\n",
        "test_scores = [0.6158, 0.6368, 0.5895, 0.5895, 0.5842, 0.4895, 0.5263, 0.5211]\n",
        "\n",
        "plt.plot(components, train_scores, label=\"Score d'apprentissage\", marker='o')\n",
        "plt.plot(components, test_scores, label=\"Score de test\", marker='o', color='red')\n",
        "plt.xlabel(\"Nombre de composantes PCA\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "id": "99220134",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous avons alors représenté ces résultats sous la forme d'un graphique, qui illustre bien la diminution de l'écart entre le score d'apprentissage et le score de test, à mesure que la dimension diminue elle aussi.   \n"
      ],
      "id": "cd2bc717"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}